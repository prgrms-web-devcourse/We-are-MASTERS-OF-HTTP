# 5주차 내용 퀴즈

## 9장 : 웹 로봇

### 1.웹 로봇이 어떤 웹사이트에 접근하고 robots.txt 를 요청했을 때, 상태 코드에 따라 어떻게 동작하나요?

<details>
<summary>퀴즈 답안</summary>
<div markdown="1">

- `2xx` : 로봇은 반드시 그 응답의 콘텐츠를 파싱하여 차단 규칙을 얻고, 그 사이트에서 무언가를 가져오려 할 때 그 규칙을 따른다.
- `404` (리소스가 존재하지 않음) : 활성화된 차단 규칙이 존재하지 않는다고 가정하고 제약 없이 사이트에 접근한다.
- `401`, `403` (접근 제한) : 로봇은 그 사이트로의 접근이 완전히 제한되어 있다고 가정
- `503` (일시적으로 실패) : 그 사이트의 리소스를 검색하는 것을 뒤로 미룬다.
- `3xx `(리다이렉션을 의미하는 경우) : 리소스가 발견될 때 까지 리다이렉트를 따라간다.

</div>
</details>

---

### 2. 다음 `robots/txt` 파일이 의미하는 바는?

```
User-agent: *
Disallow: /
User-agent: Yeti
Allow: /
```

<details>
<summary>퀴즈 답안</summary>
<div markdown="1">

다른 검색엔진의 로봇에 대하여 수집을 허용하지 않고 네이버 검색로봇(Yeti)만 수집 허용으로 설정합니다

</div>
</details>

---

## 10장 : HTTP/2.0

### 3. HTTP/1.1과 HTTP/2.0의 차이점 세 가지 이상 이야기하기

- 이러한 요소들을 통하여 `HTTP/2.0`이 `HTTP/1.1`에서 개선하고자 했던 것은?

<details>
<summary>퀴즈 답안</summary>
<div markdown="1">

프레임, 스트림, 헤더 압축, 서버 푸시

</div>
</details>
